# -*- coding: utf-8 -*-
"""
08build_graph_from_transitions.py

åŸºäºè½¦é“æ®µå˜åŠ¨ç»Ÿè®¡CSVæ„å»ºé“è·¯å›¾ç»“æ„

è¾“å…¥ï¼šCSVæ–‡ä»¶ï¼ŒåŒ…å« from_lane_id, to_lane_id, count ä¸‰åˆ—
è¾“å‡ºï¼šJSONæ ¼å¼çš„å›¾ç»“æ„ï¼Œä¸06make_node.pyæ ¼å¼ä¸€è‡´

è§„åˆ™ï¼š
- æ¯ä¸ª from_lane_id ä½œä¸ºä¸€ä¸ª node çš„ lane_idï¼ˆä»¥æ•´æ•°å½¢å¼è¾“å‡ºï¼‰
- count æœ€é«˜çš„ to_lane_id æ”¾åˆ° direct é‡Œ
- ä½äºæœ€é«˜ä½†ä»å¤§äº10è¾†çš„æ”¾è¿› near é‡Œ
- å°äºç­‰äº10çš„å…¨éƒ¨ä½œä¸ºå™ªå£°èˆå¼ƒï¼›è‹¥æŸ from_lane_id å…¨éƒ¨ <=10ï¼Œåˆ™è¯¥èŠ‚ç‚¹ç›´æ¥å¿½ç•¥
"""

import os
import json
import pandas as pd


def main(transitions_csv_path, output_json_path):
    """
    ä¸»å‡½æ•°

    å‚æ•°:
        transitions_csv_path: str, è½¦é“æ®µå˜åŠ¨ç»Ÿè®¡CSVè·¯å¾„ï¼Œéœ€åŒ…å« from_lane_id, to_lane_id, count ä¸‰åˆ—
        output_json_path: str, è¾“å‡º JSON æ–‡ä»¶è·¯å¾„
    """
    print("ğŸš€ å¼€å§‹åŸºäºè½¦é“æ®µå˜åŠ¨ç»Ÿè®¡æ„å»ºå›¾ç»“æ„...")

    # =================== Step 1: è¯»å–å˜åŠ¨ç»Ÿè®¡æ•°æ® ===================
    print("ğŸ“¦ æ­£åœ¨è¯»å–è½¦é“æ®µå˜åŠ¨ç»Ÿè®¡æ•°æ®...")
    transitions_df = pd.read_csv(transitions_csv_path)
    
    # æ£€æŸ¥å¿…è¦å­—æ®µ
    required_fields = ['from_lane_id', 'to_lane_id', 'count']
    missing_fields = [f for f in required_fields if f not in transitions_df.columns]
    if missing_fields:
        raise ValueError(f"âŒ å˜åŠ¨ç»Ÿè®¡æ•°æ®ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}")
    
    print(f"âœ… å…±è¯»å– {len(transitions_df)} æ¡å˜åŠ¨è®°å½•")
    
    # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
    transitions_df['from_lane_id'] = transitions_df['from_lane_id'].astype(str).str.strip()
    transitions_df['to_lane_id'] = transitions_df['to_lane_id'].astype(str).str.strip()
    transitions_df['count'] = transitions_df['count'].astype(int)
    
    # =================== Step 2: æŒ‰ from_lane_id åˆ†ç»„å¤„ç† ===================
    print("ğŸ” æ­£åœ¨å¤„ç†æ¯ä¸ªè½¦é“æ®µçš„è¿æ¥å…³ç³»...")
    
    graph_data = {"nodes": []}
    noise_count = 0  # ç»Ÿè®¡è¢«èˆå¼ƒçš„å™ªå£°æ•°é‡
    
    # æŒ‰ from_lane_id åˆ†ç»„
    for from_lane_id, group in transitions_df.groupby('from_lane_id'):
        # æŒ‰ count é™åºæ’åº
        sorted_group = group.sort_values('count', ascending=False)
        
        # ä»…ä¿ç•™ count > 10 çš„æœ‰æ•ˆè®°å½•
        valid_group = sorted_group[sorted_group['count'] > 10]
        noise_count += len(sorted_group) - len(valid_group)
        if valid_group.empty:
            # å½“å‰ from_lane_id æ²¡æœ‰æœ‰æ•ˆè®°å½•ï¼Œè·³è¿‡
            continue
        
        # è·å–æœ€é«˜ count å€¼ï¼ˆä¸€å®š > 10ï¼‰
        max_count = valid_group.iloc[0]['count']
        
        # åˆå§‹åŒ–è¿æ¥åˆ—è¡¨
        direct_connections = []
        near_connections = []
        
        # éå†æ‰€æœ‰æœ‰æ•ˆ to_lane_id
        for _, row in valid_group.iterrows():
            to_lane_id = row['to_lane_id']
            count = row['count']
            
            # å°† to_lane_id è½¬æ¢ä¸ºæ•´æ•°ï¼ˆå¤„ç†å¯èƒ½æ˜¯ '7.0' è¿™æ ·çš„æµ®ç‚¹æ•°å­—ç¬¦ä¸²ï¼‰
            to_lane_id_int = int(float(to_lane_id))
            
            # count æœ€é«˜çš„æ”¾å…¥ direct
            if count == max_count:
                direct_connections.append(to_lane_id_int)
            else:
                near_connections.append(to_lane_id_int)
        
        # æ„å»ºèŠ‚ç‚¹è¿æ¥å­—å…¸
        node_connections = {}
        if direct_connections:
            node_connections["direct"] = direct_connections
        if near_connections:
            node_connections["near"] = near_connections
        
        # æ·»åŠ åˆ°å›¾ç»“æ„ä¸­ï¼ˆlane_id è¾“å‡ºä¸ºæ•´æ•°ï¼‰
        lane_id_int = int(float(from_lane_id))
        graph_data["nodes"].append({
            "lane_id": lane_id_int,
            "node_connections": node_connections
        })
    
    print(f"âœ… å…±æ„å»º {len(graph_data['nodes'])} ä¸ªèŠ‚ç‚¹")
    
    # ç»Ÿè®¡è¿æ¥ä¿¡æ¯
    total_direct = sum(len(node.get('node_connections', {}).get('direct', [])) for node in graph_data['nodes'])
    total_near = sum(len(node.get('node_connections', {}).get('near', [])) for node in graph_data['nodes'])
    print(f"ğŸ“Š direct è¿æ¥æ•°: {total_direct}, near è¿æ¥æ•°: {total_near}, å™ªå£°èˆå¼ƒæ•°: {noise_count}")
    
    # =================== Step 3: è¾“å‡ºå›¾ç»“æ„ ===================
    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜å›¾ç»“æ„åˆ° {output_json_path}...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(os.path.dirname(output_json_path), exist_ok=True)
    
    # ä¿å­˜JSON
    with open(output_json_path, 'w', encoding='utf-8') as f:
        json.dump(graph_data, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ‰ å›¾ç»“æ„å·²ä¿å­˜è‡³: {output_json_path}")
    print(f"ğŸ“Š æ€»è®¡èŠ‚ç‚¹æ•°: {len(graph_data['nodes'])}")


# =================== ç¤ºä¾‹è°ƒç”¨ ===================
if __name__ == "__main__":
    
    TRANSITIONS_CSV_PATH = r"../data/road_graph/d210240930_transitions.csv"  # è½¦é“æ®µå˜åŠ¨ç»Ÿè®¡CSV
    OUTPUT_JSON = r"../data/road_graph/d210240930_graph.json"  # è¾“å‡ºè·¯å¾„

    # æ‰§è¡Œæ„å»º
    main(TRANSITIONS_CSV_PATH, OUTPUT_JSON)

