# -*- coding: utf-8 -*-
"""
08build_graph_from_transitions.py

åŸºäºè½¦é“æ®µå˜åŠ¨ç»Ÿè®¡CSVæ„å»ºé“è·¯å›¾ç»“æ„

è¾“å…¥ï¼šCSVæ–‡ä»¶ï¼ŒåŒ…å« from_lane_id, to_lane_id, count ä¸‰åˆ—
è¾“å‡ºï¼šJSONæ ¼å¼çš„å›¾ç»“æ„ï¼Œä¸06make_node.pyæ ¼å¼ä¸€è‡´

è§„åˆ™ï¼š
- æ¯ä¸ª from_lane_id ä½œä¸ºä¸€ä¸ª node çš„ lane_id
- count æœ€é«˜çš„ to_lane_id æ”¾åˆ° direct é‡Œ
- ä½äºæœ€é«˜ä½†é€šè¿‡IQRæ–¹æ³•ç­›é€‰çš„æ”¾è¿› near é‡Œï¼ˆä½¿ç”¨Q1ä½œä¸ºé˜ˆå€¼ï¼Œä½äºQ1çš„ä½œä¸ºå™ªå£°èˆå¼ƒï¼‰
- å…¶ä½™çš„ä½œä¸ºå™ªå£°èˆå¼ƒ
"""

import os
import json
import pandas as pd
import numpy as np
from collections import defaultdict


def main(transitions_csv_path, output_json_path):
    """
    ä¸»å‡½æ•°

    å‚æ•°:
        transitions_csv_path: str, è½¦é“æ®µå˜åŠ¨ç»Ÿè®¡CSVè·¯å¾„ï¼Œéœ€åŒ…å« from_lane_id, to_lane_id, count ä¸‰åˆ—
        output_json_path: str, è¾“å‡º JSON æ–‡ä»¶è·¯å¾„
    """
    print("ğŸš€ å¼€å§‹åŸºäºè½¦é“æ®µå˜åŠ¨ç»Ÿè®¡æ„å»ºå›¾ç»“æ„...")

    # =================== Step 1: è¯»å–å˜åŠ¨ç»Ÿè®¡æ•°æ® ===================
    print("ğŸ“¦ æ­£åœ¨è¯»å–è½¦é“æ®µå˜åŠ¨ç»Ÿè®¡æ•°æ®...")
    transitions_df = pd.read_csv(transitions_csv_path)
    
    # æ£€æŸ¥å¿…è¦å­—æ®µ
    required_fields = ['from_lane_id', 'to_lane_id', 'count']
    missing_fields = [f for f in required_fields if f not in transitions_df.columns]
    if missing_fields:
        raise ValueError(f"âŒ å˜åŠ¨ç»Ÿè®¡æ•°æ®ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}")
    
    print(f"âœ… å…±è¯»å– {len(transitions_df)} æ¡å˜åŠ¨è®°å½•")
    
    # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
    transitions_df['from_lane_id'] = transitions_df['from_lane_id'].astype(str).str.strip()
    transitions_df['to_lane_id'] = transitions_df['to_lane_id'].astype(str).str.strip()
    transitions_df['count'] = transitions_df['count'].astype(int)
    
    # =================== Step 2: æŒ‰ from_lane_id åˆ†ç»„å¤„ç† ===================
    print("ğŸ” æ­£åœ¨å¤„ç†æ¯ä¸ªè½¦é“æ®µçš„è¿æ¥å…³ç³»...")
    
    graph_data = {"nodes": []}
    noise_count = 0  # ç»Ÿè®¡è¢«èˆå¼ƒçš„å™ªå£°æ•°é‡
    
    # æŒ‰ from_lane_id åˆ†ç»„
    for from_lane_id, group in transitions_df.groupby('from_lane_id'):
        # æŒ‰ count é™åºæ’åº
        sorted_group = group.sort_values('count', ascending=False)
        
        # è·å–æœ€é«˜ count å€¼
        max_count = sorted_group.iloc[0]['count']
        
        # ä½¿ç”¨IQRæ–¹æ³•è®¡ç®—é˜ˆå€¼ï¼ˆé’ˆå¯¹è¯¥from_lane_idçš„æ‰€æœ‰countå€¼ï¼‰
        counts = sorted_group['count'].values
        
        # å¦‚æœåªæœ‰1ä¸ªæˆ–2ä¸ªæ•°æ®ç‚¹ï¼ŒIQRä¸é€‚ç”¨ï¼Œä½¿ç”¨ç®€å•è§„åˆ™
        if len(counts) <= 2:
            # å¦‚æœåªæœ‰1ä¸ªï¼Œç›´æ¥ä½œä¸ºdirectï¼›å¦‚æœæœ‰2ä¸ªï¼Œæœ€é«˜çš„ä½œä¸ºdirectï¼Œå¦ä¸€ä¸ªä½œä¸ºnear
            iqr_threshold = 0
        else:
            # è®¡ç®—Q1ã€Q3å’ŒIQR
            Q1 = np.percentile(counts, 25)
            Q3 = np.percentile(counts, 75)
            IQR = Q3 - Q1
            
            # ä½¿ç”¨Q1ä½œä¸ºé˜ˆå€¼ï¼ˆä½äºQ1çš„ä½œä¸ºå™ªå£°ï¼‰
            # å¯¹äº"å°‘æ•°é«˜é¢‘+å¤šæ•°ä½é¢‘"çš„åˆ†å¸ƒï¼ŒQ1ä»¥ä¸‹é€šå¸¸æ˜¯å™ªå£°
            iqr_threshold = Q1
        
        # åˆå§‹åŒ–è¿æ¥åˆ—è¡¨
        direct_connections = []
        near_connections = []
        
        # éå†æ‰€æœ‰å¯èƒ½çš„ to_lane_id
        for _, row in sorted_group.iterrows():
            to_lane_id = row['to_lane_id']
            count = row['count']
            
            # count æœ€é«˜çš„æ”¾å…¥ direct
            if count == max_count:
                direct_connections.append(int(to_lane_id))
            # ä½äºæœ€é«˜ä½†å¤§äºç­‰äºIQRé˜ˆå€¼çš„æ”¾å…¥ near
            elif count >= iqr_threshold:
                near_connections.append(int(to_lane_id))
            # å…¶ä½™èˆå¼ƒï¼ˆä½œä¸ºå™ªå£°ï¼‰
            else:
                noise_count += 1
        
        # æ„å»ºèŠ‚ç‚¹è¿æ¥å­—å…¸
        node_connections = {}
        if direct_connections:
            node_connections["direct"] = direct_connections
        if near_connections:
            node_connections["near"] = near_connections
        
        # æ·»åŠ åˆ°å›¾ç»“æ„ä¸­
        graph_data["nodes"].append({
            "lane_id": str(from_lane_id),
            "node_connections": node_connections
        })
    
    print(f"âœ… å…±æ„å»º {len(graph_data['nodes'])} ä¸ªèŠ‚ç‚¹")
    
    # ç»Ÿè®¡è¿æ¥ä¿¡æ¯
    total_direct = sum(len(node.get('node_connections', {}).get('direct', [])) for node in graph_data['nodes'])
    total_near = sum(len(node.get('node_connections', {}).get('near', [])) for node in graph_data['nodes'])
    print(f"ğŸ“Š direct è¿æ¥æ•°: {total_direct}, near è¿æ¥æ•°: {total_near}, å™ªå£°èˆå¼ƒæ•°: {noise_count}")
    
    # =================== Step 3: è¾“å‡ºå›¾ç»“æ„ ===================
    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜å›¾ç»“æ„åˆ° {output_json_path}...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(os.path.dirname(output_json_path), exist_ok=True)
    
    # ä¿å­˜JSON
    with open(output_json_path, 'w', encoding='utf-8') as f:
        json.dump(graph_data, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ‰ å›¾ç»“æ„å·²ä¿å­˜è‡³: {output_json_path}")
    print(f"ğŸ“Š æ€»è®¡èŠ‚ç‚¹æ•°: {len(graph_data['nodes'])}")


# =================== ç¤ºä¾‹è°ƒç”¨ ===================
if __name__ == "__main__":
    
    TRANSITIONS_CSV_PATH = r"../data/road_graph/d210240830_transitions.csv"  # è½¦é“æ®µå˜åŠ¨ç»Ÿè®¡CSV
    OUTPUT_JSON = r"../data/road_graph/d210240830_graph.json"  # è¾“å‡ºè·¯å¾„

    # æ‰§è¡Œæ„å»º
    main(TRANSITIONS_CSV_PATH, OUTPUT_JSON)

